<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="description"
        content="MemAgent: Reshaping Long-Context LLM with Multi-Conv RL based Memory Agent" />
    <meta name="Long context, reasoning, large lanuge model, LLM"
        content="MemAgent" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MemAgent: Reshaping Long-Context LLM with Multi-Conv RL based Memory Agent</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="./css/bulma.min.css" />
    <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="./css/index.css" />
    <link rel="stylesheet" href="./css/enhanced-styles.css" />
    <link rel="stylesheet" href="./css/final-enhancements.css" />
    <link rel="stylesheet" href="./css/navbar-fix.css" />
    <link rel="stylesheet" href="./css/navbar-alignment-fix.css" />
    <link rel="stylesheet" href="./css/overlap-fix.css" />
    <link rel="stylesheet" href="./css/spacing-fix.css" />
    <link rel="stylesheet" href="./css/author-affiliation-styles.css" />
    <link rel="icon" href="./assets/doubao.png" type="image/png" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./js/fontawesome.all.min.js"></script>
    <script src="./js/bulma-carousel.min.js"></script>
    <script src="./js/bulma-slider.min.js"></script>
    <script src="./js/index.js"></script>
    <script src="./js/enhanced-animations.js"></script>
    <script src="./js/language-switcher.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      chtml: {
        displayAlign: "center"  // âœ… å±…ä¸­æ˜¾ç¤º block å…¬å¼
      },
      loader: {
        load: ['[tex]/ams']  // å¯é€‰åŠ è½½ AMSmath å®åŒ…ç­‰
      }
    };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

    <style>
        .left-logo {
             margin-right: 1.0rem; /* è°ƒæ•´å³ä¾§é—´è·ï¼Œä½¿å¾—å…¶ä»–å…ƒç´ èƒ½å¤Ÿä¸å…¶å¯¹é½ */
            border-radius: 0; /* ç§»é™¤åœ†è§’å¤„ç† */
        }
        .equation-centered {
          text-align: center;
          margin: 2rem 0;
        }
        .nowrap-math {
            white-space: nowrap;
            display: inline-block;
        }
        .has-text-centered {
            text-align: center !important;
        }
        .has-text-centered {
            margin: 1.5rem 0;
        }
        /* é˜²æ­¢æ•°å­¦å…¬å¼æ¢è¡Œ */
        .MathJax {
            white-space: nowrap !important;
        }
        /* ç¡®ä¿å±…ä¸­çš„æ•°å­¦å…¬å¼å— */
        .math-center {
            display: block;
            text-align: center;
            margin: 1.5rem 0;
            overflow-x: auto;
        }
        .boxed-title {
        }
    </style>


</head>

<body>
    <nav class="navbar is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="container">
            <div class="navbar-brand">
                <a class="navbar-item" href="#">
                    <img src="figs/seed_logo.png" alt="Seed logo" style="height: 1.5rem; max-height: unset;" class="left-logo">
                    <img src="figs/gensi.jpg" alt="GenSI logo" style="height: 2.5rem; max-height: unset; margin-right: 0.5rem;">
                    | MemAgent
                    
                </a>
                <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                </a>
            </div>
            <div class="navbar-menu">
                <div class="navbar-end">
                    <a class="navbar-item" href="#introduction">
                        <span lang="en">Introduction</span>
                        <span lang="zh">å¼•è¨€</span>
                    </a>
                    <a class="navbar-item" href="#method">
                        <span lang="en">Method</span>
                        <span lang="zh">æ–¹æ³•</span>
                    </a>
                    <a class="navbar-item" href="#experiments">
                        <span lang="en">Experiments</span>
                        <span lang="zh">å®éªŒ</span>
                    </a>
                    <a class="navbar-item" href="#engineering">
                        <span lang="en">Engineering</span>
                        <span lang="zh">å·¥ç¨‹</span>
                    </a>
                    <a class="navbar-item" href="#citation">
                        <span lang="en">Citation</span>
                        <span lang="zh">å¼•ç”¨</span>
                    </a>
                    <button id="language-toggle" class="navbar-item language-toggle">ä¸­æ–‡</button>
                </div>
            </div>
        </div>
    </nav>
    
<section class="hero"> 
  <div class="hero-body">

    <div class="container">
        
      <div class="has-text-centered">
        <h1 class="publication-title">
        <span>
            <span lang="en"><em class="dnerf">MemAgent</em>: Reshaping Long-Context LLM with Multi-Conv RL based Memory Agent</span>
            <span lang="zh"><em class="dnerf">MemAgent</em>ï¼šReshaping Long-Context LLM with Multi-Conv RL based Memory Agent</span>
        </span>
        </h1>

        <div class="publication-authors">
          <span class="author-block"><span lang="en">Hongli Yu<sup>1,2,3</sup></span><span lang="zh">äºé¸¿åˆ©<sup>1,2,3</sup></span></span>
          <span class="author-block"><span lang="en">Tinghong Chen<sup>2</sup></span><span lang="zh">é™ˆéœ†é¸¿<sup>2</sup></span></span>
          <span class="author-block"><span lang="en">Jiangtao Feng<sup>2</sup></span><span lang="zh">å°æ±Ÿæ¶›<sup>2</sup></span></span>
          <span class="author-block"><span lang="en">Jiangjie Chen<sup>1,3</sup></span><span lang="zh">é™ˆæ±Ÿæ·<sup>1,3</sup></span></span>
          <span class="author-block"><span lang="en">Weinan Dai<sup>1,2,3</sup></span><span lang="zh">æˆ´ç‚œæ¥ <sup>1,2,3</sup></span></span>
          <span class="author-block"><span lang="en">Qiying Yu<sup>1,2,3</sup></span><span lang="zh">ç¦¹æ£‹èµ¢<sup>1,2,3</sup></span></span>
          <span class="author-block"><span lang="en">Ya-Qin Zhang<sup>2,3</sup></span><span lang="zh">å¼ äºšå‹¤<sup>2,3</sup></span></span>
          <span class="author-block"><span lang="en">Wei-Ying Ma<sup>2,3</sup></span><span lang="zh">é©¬ç»´è‹±<sup>2,3</sup></span></span>
          <span class="author-block"><span lang="en">Jingjing Liu<sup>2,3</sup></span><span lang="zh">åˆ˜èè<sup>2,3</sup></span></span>
          <span class="author-block"><span lang="en">Mingxuan Wang<sup>1,3</sup></span><span lang="zh">ç‹æ˜è½©<sup>1,3</sup></span></span>
          <span class="author-block"><span lang="en">Hao Zhou<sup>2,3</sup></span><span lang="zh">å‘¨æµ©<sup>2,3</sup></span></span>
        </div>

        <div class="publication-affiliations">
          <span class="affiliation-block">
            <span lang="en"><sup>1</sup>ByteDance Seed</span>
            <span lang="zh"><sup>1</sup>å­—èŠ‚è·³åŠ¨ Seed</span>
          </span><br>
          <span class="affiliation-block">
            <span lang="en"><sup>2</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
            <span lang="zh"><sup>2</sup>æ¸…åå¤§å­¦æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢ï¼ˆAIRï¼‰</span>
          </span><br>
          <span class="affiliation-block">
            <span lang="en"><sup>3</sup>SIA-Lab of Tsinghua AIR and ByteDance Seed</span>
            <span lang="zh"><sup>3</sup>æ¸…åå¤§å­¦ AIR ä¸å­—èŠ‚è·³åŠ¨ Seed è”åˆå®éªŒå®¤ SIA-Lab</span>
          </span>
                    </div>
                    <div class="publication-links">
                        <span class="link-block">
                          <a href="https://arxiv.org/pdf/2507.02259" class="external-link button is-dark">
                              <span class="icon">
                                  <i class="fas fa-file-pdf"></i>
                              </span>
                              <span lang="en">Paper</span>
                              <span lang="zh">è®ºæ–‡</span>
                          </a>
                        </span>
                        <span class="link-block">
                            <a href="https://github.com/BytedTsinghua-SIA/MemAgent" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-database"></i>
                                </span>
                                <span lang="en">Code</span>
                                <span lang="zh">ä»£ç </span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/hotpotqa" class="external-link button is-dark">
                                <span class="icon">
                                    ğŸ¤—
                                </span>
                                <span lang="en">Dataset</span>
                                <span lang="zh">æ•°æ®</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/BytedTsinghua-SIA/RL-MemoryAgent-14B" class="external-link button is-dark">
                                <span class="icon">
                                    ğŸ¤—
                                </span>
                                <span lang="en">Model</span>
                                <span lang="zh">æ¨¡å‹</span>
                            </a>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

<section class="section" id="introduction">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-10">
                <h2 class="title is-3">
                    <span lang="en">Introduction</span>
                    <span lang="zh">å¼•è¨€</span>
                </h2>
                <div class="content">

                    <p lang="en">
                        We propose a novel long-context processing framework â€” <strong>MemAgent</strong>, which directly optimizes long-context tasks through end-to-end Reinforcement Learning without altering the underlying model architecture. <strong>MemAgent</strong> has demonstrated superb long-context capabilities, being able to extrapolate from an 8K context trained on 32K text to a 3.5M QA task with performance loss < 5% and achieves 95%+ accuracy in 512K RULER test.
                    </p>
                    <p lang="zh">
                        æˆ‘ä»¬æ¨å‡ºäº†<strong>MemAgent</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„é•¿æ–‡æœ¬å¤„ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿé€šè¿‡ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ç›´æ¥ä¼˜åŒ–é•¿æ–‡æœ¬ä»»åŠ¡æ€§èƒ½ï¼Œè€Œæ— éœ€æ›´æ”¹åº•å±‚æ¨¡å‹æ¶æ„ã€‚<strong>MemAgent</strong> å…·æœ‰å‡ºè‰²çš„é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿä» 8K ä¸Šä¸‹æ–‡é•¿åº¦å’Œ32Kè®­ç»ƒæ•°æ®é•¿åº¦å¤–æ¨è‡³ 3.5M é—®ç­”ä»»åŠ¡ï¼Œæ€§èƒ½æŸå¤± < 5%ï¼Œå¹¶åœ¨ 512K çš„ RULER æµ‹è¯•é›†ä¸Šå–å¾— 95%+ å‡†ç¡®ç‡ã€‚
                    </p>
                    <p lang="en">
                        <strong>MemAgent</strong> achieves three core breakthroughs:
                    </p>
                    <p lang="zh">
                        <strong>MemAgent</strong> å®ç°äº†ä¸‰å¤§æ ¸å¿ƒçªç ´ï¼š
                    </p>
                    <div
                        style="background-color: #f8fafc; border-radius: 12px; border-left: 6px solid #3a76ed; padding: 1.2rem; margin-bottom: 1.5rem;">
                            <div style="display: flex; flex-direction: column; gap: 0.8rem;">
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;"> 
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        1
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>Novel memory mechanism: </strong>The agent reads text in segments and efficiently updates memory through an overwriting strategy. This design enables the model to process arbitrarily long inputs within a fixed context window, fundamentally overcoming the window length limitations of traditional Transformer architectures.</p>
                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>æ–°å‹è®°å¿†æœºåˆ¶ï¼š</strong>
                                            Agent ä»¥åˆ†æ®µæ–¹å¼è¯»å–æ–‡æœ¬ï¼Œå¹¶å€ŸåŠ©è¦†å†™ç­–ç•¥é«˜æ•ˆæ›´æ–°è®°å¿†ã€‚è¯¥è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å›ºå®šä¸Šä¸‹æ–‡çª—å£å†…å¤„ç†ä»»æ„é•¿åº¦çš„è¾“å…¥ï¼Œä»æ ¹æœ¬ä¸Šçªç ´äº†ä¼ ç»Ÿ Transformer æ¶æ„çš„çª—å£é•¿åº¦é™åˆ¶ã€‚</p>
                                    </div>
                                </div>
                                
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        2
                                    </div>
                                    <div>
                                    <p style="margin: 0; line-height: 1.4;" lang="en"><strong>O(n) complexity:</strong> By decoupling computation from text length, the complexity of processing long texts is transformed from quadratic growth to linear growth.</p>
                                    <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>O(n) çº¿æ€§å¤æ‚åº¦ï¼š</strong>
                                        å°†è®¡ç®—ä¸æ–‡æœ¬é•¿åº¦è§£è€¦ï¼Œä½¿å¾—å¤„ç†é•¿æ–‡æœ¬çš„å¤æ‚åº¦ç”±åŸæœ¬çš„äºŒæ¬¡æ–¹å¢é•¿è½¬å˜ä¸ºçº¿æ€§å¢é•¿ã€‚</p>
                                    </div>
                                </div>

                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        3
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>RL-driven extrapolation:</strong> We enhance the DAPO algorithm to support multi-turn training over context-independent conversations. Based on this, the trained model exhibits unprecedented extrapolation performance.</p>
                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„å¤–æ¨èƒ½åŠ›:</strong>
                                            æˆ‘ä»¬æ”¹è¿›äº† DAPO ç®—æ³•ï¼Œä½¿å…¶æ”¯æŒç‹¬ç«‹ä¸Šä¸‹æ–‡çš„å¤šè½®ç”Ÿæˆè®­ç»ƒã€‚ åŸºäºæ­¤è®­ç»ƒå‡ºçš„æ¨¡å‹è¡¨ç°å‡ºäº†å¯è§‚çš„å¤–æ¨æ€§èƒ½ã€‚
                                        </p>
                                    </div>
                                </div>                                
                            </div>
                    </div>

                    <strong><em style="color: #3a76ed"><p lang="en">
                        Through a simple yet effective design, we demonstrate the first truly trainable memory mechanism powered by reinforcement learning, showcasing the vast potential of using RL to optimize agent workflows.
                    </p></em></strong>
                    <strong><em style="color: #3a76ed"><p lang="zh">
                        æˆ‘ä»¬ä»¥ä¸€ç§ç®€æ´è€Œé«˜æ•ˆçš„æ–¹å¼ï¼Œé¦–æ¬¡å®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„ã€ç”±å¼ºåŒ–å­¦ä¹ èµ‹äºˆçš„å¯è®­ç»ƒè®°å¿†èƒ½åŠ›ï¼Œå……åˆ†å±•ç°äº†å¼ºåŒ–å­¦ä¹ åœ¨ä¼˜åŒ–å·¥ä½œæµæ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚
                    </p></em></strong>
                    <figure class="image" style="max-width: 1000px; margin: 2rem auto;">
                      <img src="figs/main_result_00.png" alt="Main Result Fig">
                        <figcaption>
                            <span>Accuracy scores of RULER-HotpotQA</span>
                        </figcaption>
                    </figure>

                </div>
            </div>
        </div>
    </div>
</section>


<section class="section" id="method">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-10">
                <h2 class="title is-3">
                    <span lang="en">Method</span>
                    <span lang="zh">æ–¹æ³•ä»‹ç»</span>
                </h2>
                <div class="content">
                    
                    <h4 lang="zh" class="boxed-title"><strong>Memory Agentæ¡†æ¶</strong></h4>
                    <h4 lang="en" class="boxed-title"><strong> </strong></h4>
                    <p lang="en">
                        Inspired by human behavioral patterns when processing long texts, we propose <strong>MemAgent</strong>, a novel approach for long-context processing that requires no modification to model architecture:
                        <br><strong style="color:#3273dc;">| Equipping LLMs with dynamically updating "Memory Modules"</strong>.
                    </p>
                    <p lang="zh">
                        å—äººç±»å¤„ç†é•¿æ–‡æœ¬æ—¶çš„è¡Œä¸ºæ¨¡å¼å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„çš„é•¿æ–‡å¤„ç†æ–°æ–¹æ¡ˆâ€”â€”<strong>MemAgent</strong>ï¼š
                        <br><strong style="color:#3273dc;">| ç»™LLMè£…ä¸ŠåŠ¨æ€æ›´æ–°çš„"è®°å¿†æ¨¡å—"</strong>ã€‚
                    </p>
                    
                    <figure class="image" style="max-width: 800px; margin: 2rem auto;">
                        <img src="figs/method_00.png" alt="MemAgent Architecture Overview">
                            <figcaption>
                                <span>MemAgent Architecture Overview</span>
                            </figcaption>
                    </figure>
                    
                    <p lang="en">
                        <strong>MemAgent</strong> introduces a fixed-length auxiliary memory panel that enables the model to process long texts in a segmented manner, actively updating the memory state after each segment to achieve a novel "local processing + global fusion" workflow. This memory module continuously updates dynamically during inference and, after all segments are processed, assists in generating the final output by aggregating critical information stored in memory.
                    </p>
                    <p lang="zh">
                        <strong>MemAgent</strong>å¼•å…¥äº†ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¾…åŠ©è®°å¿†é¢æ¿ï¼Œå…è®¸æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶ä»¥åˆ†æ®µçš„æ–¹å¼è¯»å–è¾“å…¥ï¼Œå¹¶åœ¨æ¯ä¸€æ®µä¹‹åä¸»åŠ¨æ›´æ–°è®°å¿†çŠ¶æ€ï¼Œä»è€Œå®ç°"å±€éƒ¨å¤„ç† + å…¨å±€èåˆ"çš„æ–°å‹å·¥ä½œæµã€‚è¯¥è®°å¿†æ¨¡å—åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸æ–­åŠ¨æ€æ›´æ–°ï¼Œå¹¶åœ¨æ‰€æœ‰æ®µè½å¤„ç†å®Œæ¯•åï¼Œé€šè¿‡èšåˆè®°å¿†ä¸­çš„å…³é”®ä¿¡æ¯ååŠ©ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚
                    </p>



                    <h4 lang="zh" class="boxed-title"><strong>å¤šè½®å¯¹è¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒ MemAgent </strong></h4>
                    <h4 lang="en" class="boxed-title"><strong>Training MemAgent with Multi-conv RL </strong></h4>
                    <p lang="en">
                        We employ Reinforcement Learning from Verifiable Rewards (RLVR), which currently demonstrates exceptional performance in the reasoning domain, to train <strong>MemAgent</strong>, rather than simply performing fine-tuning or instruction engineering. To this end, we extend the existing DAPO algorithm to further support end-to-end optimization of Agent Workflows with multi-turn context-independent conversations.
                    </p>
                    <p lang="zh">
                        æˆ‘ä»¬ä½¿ç”¨ç›®å‰åœ¨æ¨ç†é¢†åŸŸè¡¨ç°å‡ºå“è¶Šæ€§èƒ½çš„åŸºäºå¯éªŒè¯ç»“æœçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰æ¥è®­ç»ƒ<strong>MemAgent</strong>ï¼Œè€Œéç®€å•çš„è¿›è¡Œå¾®è°ƒæˆ–æŒ‡ä»¤å·¥ç¨‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ‰©å±•äº†ç°æœ‰çš„DAPOç®—æ³•ï¼Œä½¿å…¶è¿›ä¸€æ­¥æ”¯æŒäº†å…·æœ‰å¤šè½®ç‹¬ç«‹å¯¹è¯çš„Agent Workflowçš„ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚
                    </p>

                    <div class="columns is-vcentered">
                        <div class="column">
                            <figure class="image">
                                <img src="figs/algo_00.png" alt="Comparison between vanilla GRPO and Multi-Conv DAPO">
                                <figcaption>
                                    <span>Comparison between vanilla GRPO and Multi-Conv DAPO</span>
                                  </figcaption>
                            </figure>
                        </div>
                        <div class="column">
                            <figure class="image">
                                <img src="figs/template.png" alt="Template of MemAgent for context processing (top part) and final answer generation (bottom)" style="width: 120%;">
                                <figcaption>
                                    <span>Template of MemAgent</span>
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p lang="en"><strong>Multi-Conv Training Mechanism:</strong> For each input sample, the model generates multiple responses, where each response cannot be obtained by simply concatenating previous generation trajectories but has independent inputs, differing from the approach in tool calling that uses multi-turn concatenated trajectories as input.</p>
                    <p lang="zh"><strong>å¤šè½®å¯¹è¯è®­ç»ƒæœºåˆ¶ï¼š</strong>å¯¹äºæ¯ä¸ªè¾“å…¥æ ·æœ¬ï¼Œæ¨¡å‹ç”Ÿæˆå¤šæ¬¡å›ç­”ï¼Œæ¯æ¬¡å›ç­”çš„è¾“å…¥ä¸èƒ½é€šè¿‡ç®€å•çš„æ‹¼æ¥æ­¤å‰çš„ç”Ÿæˆè½¨è¿¹è·å¾—ï¼Œè€Œæ˜¯å…·æœ‰ç‹¬ç«‹çš„è¾“å…¥ï¼ŒåŒºåˆ«äºå·¥å…·è°ƒç”¨ä¸­ä½¿ç”¨å¤šè½®æ‹¼æ¥è½¨è¿¹ä½œä¸ºè¾“å…¥çš„æ–¹å¼ã€‚</p>
                    <p lang="en"><strong>Reward Computation:</strong> The final answer is extracted based from the last turn of conversation.  The advantage is computed through rule-based outcome reward and group normalization and then be allocated to all associated conversations.</p>
                    <p lang="zh"><strong>å¥–åŠ±è®¡ç®—ï¼š</strong>ä»æœ€åä¸€è½®å›ç­”ä¸­æå–æœ€ç»ˆç­”æ¡ˆï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„ç»“æœå¥–åŠ±å¹¶é€šè¿‡ç»„å½’ä¸€åŒ–è®¡ç®—ä¼˜åŠ¿ï¼Œå°†å…¶åˆ†é…åˆ°æ‰€æœ‰å…³è”å¯¹è¯ã€‚</p>

                    <p lang="en"><strong>Policy Optimization:</strong> Each conversation serves as an optimization target, with DAPO-style token-level averaged loss calculated based on its advantage.</p>
                    <p lang="zh"><strong>ä¼˜åŒ–ç­–ç•¥ï¼š</strong>ä»¥æ¯è½®å¯¹è¯ä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œæ ¹æ®å…¶ä¼˜åŠ¿è®¡ç®—ç±»DAPOçš„token-levelå¹³å‡æŸå¤±ã€‚</p>
                    <div class="math-center">
                      $$
                      \begin{aligned}
                      \mathcal{J}_{\text{DAPO}}(\theta) =\quad &\mathbb{E}_{(q,a)\sim \mathcal{D}, \{o_{i,j}\}_{i=1}^G\sim \pi_{\theta_\text{old}}(\cdot\mid q,~o_{i,j-1})} \\
                      &\Bigg[\frac{1}{\sum_{i=1}^{G}\sum_{j=1}^{n_i}|o_{i,j}|}\sum_{i=1}^{G}\sum_{j=1}^{n_i}\sum_{t=1}^{|o_{i,j}|}
                      \Big(\mathcal{C}_{i,j,t} - \beta D_{\text{KL}}(\pi_{\theta} || \pi_{\text{ref}} )\Big) \Bigg] \\
                      \text{where } \mathcal{C}_{i,j,t} = &\min\Big(r_{i,j,t}(\theta) \hat{A}_{i,j,t},  
                      \ \text{clip} \Big( r_{i,j,t}(\theta), 1 - {\varepsilon_{low}}, 1 + {\varepsilon_{high}} \Big) \hat{A}_{i,j,t}\Big)
                      \end{aligned}
                      $$
                    </div>

                    <h4 lang="zh" class="boxed-title"><strong>é‡æ–°å»ºæ¨¡è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ </strong></h4>
                    <h4 lang="en" class="boxed-title"><strong>Re-modeling the Language Model Generation Process</strong></h4>
                    <p lang="en" class="boxed-title"><strong>Traditional Text Modeling:</strong></p>
                    <p lang="en">
                        Traditional autoregressive language models model token sequences of length N through the following approach:
                    </p>
                    <h5 lang="zh" class="boxed-title"><strong>ä¼ ç»Ÿæ–‡æœ¬å»ºæ¨¡ï¼š</strong></h5>
                    <p lang="zh">
                        ä¼ ç»Ÿçš„è‡ªå›å½’è¯­è¨€æ¨¡å‹é€šè¿‡ä»¥ä¸‹æ–¹å¼å»ºæ¨¡é•¿åº¦ä¸ºNçš„tokenåºåˆ—ï¼š
                    </p>
                    <div class="math-center">
                        $p(\mathbf{x}_{1:N}) = p(x_1) \prod_{n=2}^{N} p(x_n \mid \mathbf{x}_{1:n-1})$
                    </div>
                    <p lang="en">
                        This method requires attention computation over all previously generated tokens, leading to a cost of <span class="nowrap-math">$O(N^2)$</span>.
                    </p>
                    <p lang="zh">
                        è¿™ç§æ–¹æ³•éœ€è¦å¯¹æ‰€æœ‰å…ˆå‰ç”Ÿæˆçš„tokenè®¡ç®—æ³¨æ„åŠ›ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬éšåºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢é•¿ã€‚
                    </p>

                    <h5 lang="en" class="boxed-title"><strong>Rethinking MemAgent from LM Perspectives</strong></h5>
                    <p lang="en">
                      To get a deeper sense of the <strong>MemAgent</strong> design, we propose to re-think language-model factorization in the following fashion. 
                    </p>
                    <h5 lang="zh" class="boxed-title"><strong>ä»è¯­è¨€æ¨¡å‹çš„è§’åº¦é‡æ–°ç†è§£ MemAgent</strong></h5>
                    <p lang="zh">
                        ä¸ºäº†è¿›ä¸€æ­¥åœ°ç†è§£ <strong>MemAgent</strong>çš„è®¾è®¡ï¼Œæˆ‘ä»¬è€ƒè™‘ä¸‹åˆ—å¯¹è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹çš„æ–°å»ºæ¨¡æ–¹å¼ã€‚
                    </p>
                    <!--  -->
                    <p lang="en" >Specifically, the input sequence is segmented into K contiguous chunks <span class="nowrap-math">\((c^1, c^2, \ldots, c^K)\)</span>, with each chunk containing at most <span class="nowrap-math">\(C\)</span> tokens.</p>
                    <p lang="en" >Let <span class="nowrap-math"> \(m^{1:K-1}\)</span> denoteds the latent memory variables and initial state <span class="nowrap-math">\(m^0 = \emptyset\)</span>, the autoregressive factorization is reformulated as a series of chunk processing and reading and writing to the memory:</p>
                    
                    <!--  -->
                    <p lang="zh" >å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†è¾“å…¥åºåˆ—åˆ†å‰²ä¸ºKä¸ªè¿ç»­å— <span class="nowrap-math">\((c^1, c^2, \ldots, c^K)\)</span>ï¼Œæ¯å—æœ€å¤šåŒ…å« <span class="nowrap-math">\(C\)</span> ä¸ªtokenã€‚</p>
                    <p lang="zh" >å¼•å…¥è¡¨ç¤ºè®°å¿†çš„éšå˜é‡<span class="nowrap-math">\(m^{1:K-1}\)</span>å¹¶ç»™å®šåˆå§‹çŠ¶æ€<span class="nowrap-math">\(m^0 = \emptyset\)</span>åï¼Œè‡ªå›å½’è¿‡ç¨‹å¯é‡æ–°è¡¨è¿°ä¸ºä¸€ç³»åˆ—å¯¹è¾“å…¥å—çš„å¤„ç†å¹¶è¯»å†™memoryçš„è¿‡ç¨‹ï¼š</p>

                    <div class="math-center">
                          $p(\mathbf{x}_{1:N}) = \sum_{\mathbf{m}^{1:K-1}} \prod_{k=1}^{K}
                          \underbrace{p(\mathbf{c}^k \mid \mathbf{m}^{k-1})}_{\text{read}} \cdot
                          \underbrace{p(\mathbf{m}^k \mid \mathbf{c}^k, \mathbf{m}^{k-1})}_{\text{write}}$
                    </div>

                    <p lang="en" >The new modeling bounds the context window of each conversation within a fixed size, yielding a <span class="nowrap-math">$O(N)$</span> computational cost.</p>
                    <!--  -->
                    <p lang="zh" >æ–°çš„å»ºæ¨¡æ–¹å¼å°†æ¯æ¬¡å¯¹è¯çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°é™åˆ¶åœ¨å¸¸æ•°èŒƒå›´å†…ï¼Œæœ€ç»ˆçš„è®¡ç®—å¤æ‚åº¦ä¸º <span class="nowrap-math">$O(N)$</span>ã€‚</p>

                </div>
            </div>
        </div>
    </div>
</section>

<section class="section" id="experiments">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Experiments</span>
          <span lang="zh">å®éªŒåˆ†æ</span>
        </h2>
        <div class="content">

          <h4 lang="en"><strong>Main Results</strong></h4>
          <h4 lang="zh"><strong>ä¸»å®éªŒç»“æœ</strong></h4>

          <p lang="en">
            <strong>Baseline Models:</strong> Experimental results demonstrate that existing models exhibit significant performance degradation when confronted with ultra-long contexts.
            <ul lang="en">
              <li><strong>DS-distill series:</strong> Performance within context rapidly decays to extremely low levels as length increases, becoming essentially ineffective beyond the context window due to information loss.</li>
              <li><strong>QwenLong-L1:</strong> With post-training length of 60K, performance decline within this range is approximately 10%. While the degradation from 64K to 112K exceeds 28%, despite remaining within the context window length.</li>
              <li><strong>Qwen2.5-Instruct-1M series:</strong> Performance decline within context is gradual, but performance drops to zero at 896K testing, still within the 1M context length range.</li>
            </ul>
          </p>

          <p lang="zh">
            <strong>åŸºçº¿æ¨¡å‹ï¼š</strong> å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨é¢å¯¹è¶…é•¿åºåˆ—æ—¶å‡å‡ºç°æ˜¾è‘—çš„æ€§èƒ½é€€åŒ–ï¼š
            <ul lang="zh">
              <li><strong>DS-distillç³»åˆ—ï¼š</strong>Context windowå†…æ€§èƒ½éšé•¿åº¦è¿…é€Ÿè¡°å‡åˆ°æä½æ°´å¹³ï¼Œè¶…å‡ºcontext windowå› ä¸¢å¤±ä¿¡æ¯åŸºæœ¬å¤±æ•ˆã€‚</li>
              <li><strong>QwenLong-L1ï¼š</strong>åè®­ç»ƒé•¿åº¦ä¸º60Kï¼Œåœ¨æ­¤ä¹‹å†…çš„æ€§èƒ½ä¸‹é™çº¦ä¸º10%ã€‚ä»64Kåˆ°112Kçš„ä¸‹é™åˆ™è¶…è¿‡28%ï¼Œå°½ç®¡æ­¤æ—¶å°šåœ¨context windowé•¿åº¦ä¹‹å†…ã€‚</li>
              <li><strong>Qwen2.5-Instruct-1Mç³»åˆ—ï¼š</strong>contextå†…æ€§èƒ½ä¸‹é™å¹³ç¼“ï¼Œä½†åœ¨å°šåœ¨1Mä¸Šä¸‹æ–‡é•¿åº¦èŒƒå›´å†…çš„896Kæµ‹è¯•ä¸Šä¾¿å·²é™è‡³0ã€‚</li>
            </ul>
          </p>

          <p lang="en">
            <strong>RL-MemAgent:</strong> In contrast, RL-MemAgent demonstrates exceptional stability in ultra-long context processing:
            <ul lang="en">
              <li><strong>RL-MemAgent-14B:</strong> Performance degradation <5.5% on 3.5M token tasks, achieving truly lossless extrapolation.</li>
              <li><strong>RL-MemAgent-7B:</strong> Only 11% performance decline in the longest contexts, with overall performance far exceeding existing long-context models.</li>
            </ul>
          </p>

          <p lang="zh">
            <strong>RL-MemAgentï¼š</strong> ç›¸æ¯”ä¹‹ä¸‹ï¼ŒRL-MemAgentåœ¨è¶…é•¿æ–‡æœ¬å¤„ç†ä¸­å±•ç°äº†ä¼˜å¼‚çš„ç¨³å®šæ€§ï¼š
            <ul lang="zh">
              <li><strong>RL-MemAgent-14Bï¼š</strong>åœ¨3.5M tokenä»»åŠ¡ä¸Šæ€§èƒ½ä¸‹é™<5.5%ï¼Œå®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„æ— æŸå¤–æ¨ã€‚</li>
              <li><strong>RL-MemAgent-7Bï¼š</strong>åœ¨æœ€é•¿æ–‡æœ¬ä¸Šä»…å‡ºç°11%çš„æ€§èƒ½ä¸‹é™ï¼Œæ•´ä½“è¡¨ç°è¿œè¶…ç°æœ‰é•¿æ–‡æœ¬æ¨¡å‹ã€‚</li>
            </ul>
          </p>

          <figure class="image" style="max-width: 900px; margin: 2rem auto;">
            <img src="figs/main_result.png" alt="Main experimental results">
            <figcaption>
              <span>Main experimental results</span>
            </figcaption>
          </figure>


          <h4 lang="en"><strong>Ablation Study</strong></h4>
          <h4 lang="zh"><strong>æ¶ˆèå®éªŒ</strong></h4>

          <p lang="en">
                To validate the necessity of using reinforcement learning for Memory Agent training, we conduct comprehensive ablation experiments.
                <ul lang="en">
                  <li><strong>Base Model:</strong> The original model exhibits severe performance degradation as context length increases, particularly after 112K where inputs are truncated due to context window limitations, making effective extrapolation nearly impossible.</li>
                  <li><strong>MemAgent (w/o RL):</strong> Compared to the base model, it demonstrates better performance and maintains reasonable capability on tasks exceeding the context length, but still experiences overall performance decline as input length increases.</li>
                  <li><strong>RL-MemAgent:</strong>The RL-trained <strong>MemAgent</strong> maintains near-lossless extrapolation capability across all context lengths.</li>
                </ul>
          </p>

          <p lang="zh">
                æˆ‘ä»¬è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„æ¶ˆèå®éªŒï¼ŒéªŒè¯ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¯¹MemAgentè¿›è¡Œè®­ç»ƒçš„å¿…è¦æ€§ã€‚
                <ul lang="zh">
                  <li><strong>åŸºç¡€æ¨¡å‹ï¼š</strong> åŸå§‹æ¨¡å‹éšç€ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ è¡¨ç°å‡ºä¸¥é‡çš„æ€§èƒ½ä¸‹é™ï¼Œç‰¹åˆ«æ˜¯åœ¨112Kä¹‹åï¼Œç”±äºä¸Šä¸‹æ–‡çª—å£é™åˆ¶å¯¼è‡´è¾“å…¥è¢«æˆªæ–­ï¼Œä½¿å¾—æœ‰æ•ˆå¤–æ¨å‡ ä¹ä¸å¯èƒ½å®ç°ã€‚</li>
                  <li><strong>MemAgentï¼ˆw/o RLï¼‰ï¼š</strong> ç›¸è¾ƒäºåŸºç¡€æ¨¡å‹è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œåœ¨è¶…å‡ºä¸Šä¸‹æ–‡é•¿åº¦çš„ä»»åŠ¡ä¸­ä¿æŒä¸€å®šæ°´å¹³çš„èƒ½åŠ›ï¼Œä½†éšç€è¾“å…¥é•¿åº¦å¢åŠ ä»ç„¶å‡ºç°æ•´ä½“æ€§èƒ½ä¸‹é™ã€‚</li>
                  <li><strong>RL-MemAgentï¼š</strong> ç»è¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„<strong>MemAgent</strong>åœ¨æ‰€æœ‰ä¸Šä¸‹æ–‡é•¿åº¦ä¸­ä¿æŒè¿‘ä¹æ— æŸçš„å¤–æ¨èƒ½åŠ›ã€‚</li>
                </ul>
          </p>

          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/ablation_00.png" alt="Ablation study on RULER-HotpotQA">
                <figcaption>
                    <span>Ablation study on RULER-HotpotQA</span>
                </figcaption>
          </figure>

          <h4 lang="en"><strong>Other OOD Task in RULER Benchmark</strong></h4>
          <h4 lang="zh"><strong>RULERåŸºå‡†æµ‹è¯•ä¸­çš„å…¶ä»–OODä»»åŠ¡</strong></h4>

          <p lang="en">
            <strong>RULER</strong> is the current standard test set for long-text extrapolation capability research, with the core advantage of controllable length generation tasks. We utilize synthetic QA data based on HotpotQA for training.
          </p>

          <p lang="zh">
            <strong>RULERåŸºå‡†æµ‹è¯•</strong> æ˜¯å½“å‰é•¿æ–‡æœ¬å¤–æ¨èƒ½åŠ›ç ”ç©¶çš„æ ‡å‡†æµ‹è¯•é›†ï¼Œå…¶æ ¸å¿ƒä¼˜åŠ¿æ˜¯å¯æ§é•¿åº¦ç”Ÿæˆä»»åŠ¡ã€‚è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»HotpotQAåˆæˆçš„QAæ•°æ®ã€‚
          </p>

          <div class="box" style="background: #f8f9fa; border: 1px solid #ddd; border-radius: 10px; padding: 1.5rem;">
            <div class="columns is-multiline is-variable is-4">
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Needle-in-a-Haystack(NIAH)</strong>
                  <strong lang="zh">å¤§æµ·æé’ˆï¼ˆNIAHï¼‰</strong>
                  <p lang="en">Locating key needles in ultra-long texts, including 8 types of interference variants.</p>
                  <p lang="zh">åœ¨è¶…é•¿æ–‡æœ¬ä¸­å®šä½å…³é”®needleï¼ŒåŒ…å«8ç±»å¹²æ‰°å˜ä½“ã€‚</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Variable Tracking(VT)</strong>
                  <strong lang="zh">å˜é‡è¿½è¸ªï¼ˆVTï¼‰</strong>
                  <p lang="en">Simulating program analysis scenarios, tracking variable references and assignment relationships.</p>
                  <p lang="zh">æ¨¡æ‹Ÿç¨‹åºåˆ†æåœºæ™¯ï¼Œè¿½è¸ªå˜é‡å¼•ç”¨å’Œèµ‹å€¼å…³ç³»ã€‚</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Aggregation(Agg)</strong>
                  <strong lang="zh">èšåˆä»»åŠ¡ï¼ˆAggï¼‰</strong>
                  <p lang="en">Aggregating scattered information to evaluate the model's ability to grasp global features.</p>
                  <p lang="zh">æ±‡æ€»åˆ†æ•£ä¿¡æ¯ï¼Œè¯„ä¼°æ¨¡å‹å¯¹å…¨å±€ç‰¹å¾çš„æŒæ¡èƒ½åŠ›ã€‚</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Question Answering (QA)</strong>
                  <strong lang="zh">é—®ç­”ä»»åŠ¡ï¼ˆQAï¼‰</strong>
                  <p lang="en">Conducting multi-hop complex reasoning to test the model's contextual understanding and QA capabilities.</p>
                  <p lang="zh">è¿›è¡Œå¤šè·³å¤æ‚æ¨ç†ï¼Œæµ‹è¯•æ¨¡å‹ä¸Šä¸‹æ–‡ç†è§£ä¸é—®ç­”èƒ½åŠ›ã€‚</p>
                </div>
              </div>
            </div>
          </div>

          <p lang="en">
                <strong>OOD Experiments:</strong> We test out model in 10 untrained tasks and QA task synthesized from a new dataset, SQuAD. We use heatmaps to visualize the performance of different models across different length ranges and task types. Our model achieves a SOTA in this two OOD tests and the 14B model achieves 95%+ average score over 10 OOD RULER tests in 512K context length. 
          </p>

          <p lang="zh">
                <strong>OODå®éªŒï¼š</strong> æˆ‘ä»¬åœ¨10ä¸ªæœªè®­ç»ƒä»»åŠ¡å’Œä½¿ç”¨æ–°æ•°æ®é›†ï¼ˆSQuADï¼‰åˆæˆçš„é—®ç­”ä»»åŠ¡ä¸Šæµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼Œä½¿ç”¨çƒ­åŠ›å›¾å¯è§†åŒ–ä¸åŒæ¨¡å‹åœ¨ä¸åŒé•¿åº¦åŒºé—´å’Œä»»åŠ¡ç±»å‹ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨è¿™ä¸¤ä¸ªOODæµ‹è¯•ä¸­å‡å–å¾—SOTAè¡¨ç°ï¼Œå…¶ä¸­14Bæ¨¡å‹åœ¨512Kä¸Šä¸‹æ–‡é•¿åº¦ä¸‹çš„10ä¸ªOOD RULERæµ‹è¯•ä¸­å–å¾—95%+çš„å¹³å‡åˆ†æ•°ã€‚
          </p>

          <div class="columns is-multiline">
            <div class="column is-6" width="60%">
              <figure class="image" ><img src="figs/avg_00.png" alt="AVG">
                  <figcaption>
                    <span>RULER average across 10 tasks</span>
                  </figcaption>
              </figure>
                
            </div>
            <div class="column is-6"  width="40%">
              <figure class="image"><img src="figs/qa_1_00.png" alt="QA_1">
                  <figcaption>
                    <span>RULER-QA task from SQuAD</span>
                  </figcaption>
              </figure>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="conclusion">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Conclusion</span>
          <span lang="zh">æ€»ç»“</span>
        </h2>
        <div class="content">
            <p lang="zh">
                æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„é•¿æ–‡æœ¬å¤„ç†æ¡†æ¶ <strong>MemAgent</strong>ï¼Œåœ¨ä»¥ä¸‹ä¸‰ä¸ªå…³é”®ç»´åº¦å®ç°äº†é‡è¦çªç ´ï¼š
            </p>
            <p lang="en">
                In this work, we propose a novel framework for long-context processing, with contributions spanning three key dimensions:
            </p>
                      <div
                        style="background-color: #f8fafc; border-radius: 12px; border-left: 6px solid #3a76ed; padding: 1.2rem; margin-bottom: 1.5rem;">
                            <div style="display: flex; flex-direction: column; gap: 0.8rem;">
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;"> 
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        1
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>Architectural Innovation:</strong> We introduce an innovative mechanism that enables large language models to process arbitrarily long input sequences within a limited context window and with <strong>linear-time complexity</strong>, fundamentally addressing the computational bottlenecks faced by traditional long-context methods.</p>

                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>æŠ€æœ¯æ¶æ„çªç ´ï¼š</strong>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æœºåˆ¶ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåœ¨æœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£å†…ä»¥<strong>çº¿æ€§æ—¶é—´å¤æ‚åº¦</strong>å¤„ç†ä»»æ„é•¿åº¦çš„è¾“å…¥æ–‡æœ¬ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†ä¼ ç»Ÿé•¿æ–‡æœ¬æ–¹æ³•é¢ä¸´çš„è®¡ç®—ç“¶é¢ˆé—®é¢˜ã€‚</p>
                                    </div>
                                </div>
                                
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        2
                                    </div>
                                    <div>
                                    <p style="margin: 0; line-height: 1.4;" lang="en"><strong>Agent Training Methodology:</strong> We design a complete agent workflow to implement this mechanism, and develop an end-to-end training framework based on <strong>Multi-conv RL</strong>, enabling the agent to learn how to store and retrieve relevant information effectively.</p>

                                    <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>æ™ºèƒ½ä½“è®­ç»ƒæ–¹æ³•ï¼š</strong>
                                        æˆ‘ä»¬è®¾è®¡äº†ä¸€å¥—å®Œæ•´çš„æ™ºèƒ½ä½“å·¥ä½œæµæ¥å®ç°ä¸Šè¿°æœºåˆ¶ï¼Œå¹¶åŸºäº<strong>å¤šè½®å¯¹è¯å¼ºåŒ–å­¦ä¹ </strong>ä¸ºè¯¥æ™ºèƒ½ä½“è®¾è®¡äº†ç«¯åˆ°ç«¯çš„è®­ç»ƒæ¡†æ¶ã€‚</p>
                                    </div>
                                </div>

                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        3
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>Extrapolation Performance:</strong> Through extensive empirical evaluation, we demonstrate that our Multi-conv RL method allows models to extrapolate far beyond their training context length with almost <strong>lossless performance</strong> during testing, substantially expanding the capability frontier of current long-context LLM systems.</p>

                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>æ€§èƒ½å¤–æ¨éªŒè¯ï¼š</strong>
                                            é€šè¿‡å¤§é‡å®éªŒéªŒè¯ï¼Œæˆ‘ä»¬è¯æ˜äº†åŸºäºå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ–¹æ³•èƒ½å¤Ÿè®©æ¨¡å‹æˆåŠŸ<strong>æ— æŸå¤–æ¨</strong>åˆ°è¿œè¶…è®­ç»ƒé•¿åº¦çš„æ–‡æ¡£ä¸Šï¼Œå¤§å¹…æ‰©å±•äº†å½“å‰é•¿æ–‡æœ¬å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„å¤„ç†è¾¹ç•Œã€‚</p>
                                    </div>
                                </div>                                
                            </div>
                    </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="engineering">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Engineering Design</span>
          <span lang="zh">å·¥ç¨‹è®¾è®¡</span>
        </h2>

        <div class="content">
          <p lang="zh">
            æˆ‘ä»¬åŸºäºverlå®ç°äº†åŸºç¡€çš„Multi-Conv DAPOè®­ç»ƒä»£ç ï¼Œå®ƒå®šä¹‰äº†Multi-Convå·¥ä½œæµã€æ•°æ®é›†ã€é…ç½®é¡¹çš„ç»Ÿä¸€æ¥å£ï¼Œå¯æ–¹ä¾¿åœ°æ¥å…¥æ–°çš„å®ç°ã€‚
          </p>
          <p lang="en">
            We implement a basic Multi-Conv DAPO training code based on verl, which defines a unified interface for Multi-Conv workflow, dataset, and configuration items.
          </p>
        </div>

        <div class="content">
          <p lang="zh">
            æˆ‘ä»¬è¿›ä¸€æ­¥å®ç°äº†ä¸€ä¸ªçº¯å¼‚æ­¥çš„è®­ç»ƒæ¡†æ¶ï¼Œä½¿ç”¨ç»Ÿä¸€æ¥å£åšåˆ°äº†<strong>â€œAgent as a functionâ€</strong>ï¼Œä»…éœ€å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå³å¯å®ç°ä»»æ„agent workflowã€‚
          </p>
          <ul lang="zh">
            <li><strong>çº¯å¼‚æ­¥æµæ°´çº¿ï¼š</strong> GPU/CPUèµ„æºè§£è€¦ï¼Œ<code>AsyncLLMEngine</code> è´Ÿè´£å¤šèŠ‚ç‚¹æ¨ç†ï¼Œ<code>Ray Worker</code>ç®¡ç†å¸¸é©»CPUä»»åŠ¡æ± ï¼Œé€šè¿‡åç¨‹å®Œæˆèµ„æºè°ƒåº¦ã€‚</li>
            <li><strong>ç»Ÿä¸€APIæ¥å£ï¼š</strong> ä½¿ç”¨ OpenAI API é£æ ¼çš„æ¥å£è°ƒç”¨LLMï¼Œæ”¯æŒ <strong>å¤šè½®å·¥å…·è°ƒç”¨ã€å¤šè½®ç‹¬ç«‹å¯¹è¯</strong>ï¼Œæ¶ˆé™¤ä¼ ç»Ÿçš„å¤§é‡å†—ä½™ä»£ç åœ°ç‹±ã€‚</li>
          </ul>

          <p lang="en">
              We further implement a fully asynchronous training framework that achieves <strong>"Agent as a Function"</strong> through a unified interface, requiring only the definition of a single function to implement arbitrary agent workflows.
          </p>
          <ul lang="en">
            <li><strong>Fully Asynchronous Pipeline:</strong> GPU and CPU resources are decoupled. <code>AsyncLLMEngine</code> handles multi-node inference while <br/><code>Ray Worker</code> manages a persistent process pool, and task scheduling is completed via <code>async</code> coroutines.</li>
            <li><strong>Unified API Interface:</strong> Unified API Interface with OpenAI-style API, supporting <strong>multi-turn tool use, multi-agent parallelism, and multi-task training</strong>, eliminating traditional state machine boilerplate.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>




    <section class="section" id="citation">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3">
                        <span lang="en">ğŸ“ Citation</span>
                        <span lang="zh">ğŸ“ å¼•ç”¨</span>
                    </h2>
                    <div class="content">
                        <p lang="en">If you find this work useful, please cite our paper:</p>
                        <p lang="zh">å¦‚æœæ‚¨å‘ç°è¿™é¡¹å·¥ä½œæœ‰ç”¨ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š</p>
                        <pre><code class="latex">
@article{memagent,
  title={MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent},
  author={Yu, Hongli and Chen, Tinghong and Feng, Jiangtao and Chen, Jiangjie and Dai, Weinan and Yu, Qiying and others},
  journal={arXiv preprint arXiv:2507.02259},
  year={2025}
}

                        </code></pre>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="has-text-centered">
                <p>
                    <span lang="en">Â© 2025 <a href="https://seed.bytedance.com">ByteDance Seed</a>. Modified from <a href="https://github.com/seed-enigmata/seed-enigmata.github.io">R2E-Gym</a>.</span>
                    <span lang="zh">Â© 2025 <a href="https://seed.bytedance.com">å­—èŠ‚è·³åŠ¨Seed</a>. ä¿®æ”¹è‡ª <a href="https://github.com/seed-enigmata/seed-enigmata.github.io">R2E-Gym</a>.</span>
                </p>
            </div>
        </div>
    </footer>


</body>



</html>
